"""
W&B ì‹œê°í™” ìœ í‹¸ë¦¬í‹°
- ê²€ì¦/í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì™€ ë°”ìš´ë”© ë°•ìŠ¤ ì‹œê°í™”
- ì‹¤ì œ vs ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ
- í•™ìŠµ ì§„í–‰ìƒí™© ì‹œê°ì  ëª¨ë‹ˆí„°ë§
"""

import wandb
import cv2
import numpy as np
from pathlib import Path
import random
from ultralytics import YOLO
import yaml


class WandBVisualizer:
    def __init__(self, class_names):
        """
        W&B ì‹œê°í™” í´ë˜ìŠ¤ ì´ˆê¸°í™”

        Args:
            class_names: í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ['crack', 'efflorescence', 'spalling']
        """
        self.class_names = class_names
        self.colors = self._generate_colors()

    def _generate_colors(self):
        """í´ë˜ìŠ¤ë³„ ê³ ìœ  ìƒ‰ìƒ ìƒì„±"""
        colors = {}
        for i, name in enumerate(self.class_names):
            # ê· ì—´=ë¹¨ê°•, ë°±íƒœ=íŒŒë‘, ë°•ë¦¬=ì´ˆë¡ ë“± êµ¬ë¶„ë˜ëŠ” ìƒ‰ìƒ
            if 'crack' in name.lower():
                colors[name] = (255, 0, 0)  # ë¹¨ê°•
            elif 'efflorescence' in name.lower():
                colors[name] = (0, 0, 255)  # íŒŒë‘
            elif 'spalling' in name.lower():
                colors[name] = (0, 255, 0)  # ì´ˆë¡
            else:
                # ê¸°íƒ€ í´ë˜ìŠ¤ëŠ” ë¬´ì‘ìœ„ ìƒ‰ìƒ
                colors[name] = tuple(np.random.randint(0, 255, 3).tolist())
        return colors

    def draw_boxes(self, image, boxes, labels, scores=None, title_prefix=""):
        """
        ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°

        Args:
            image: numpy ì´ë¯¸ì§€ ë°°ì—´
            boxes: ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ [[x1,y1,x2,y2], ...]
            labels: í´ë˜ìŠ¤ ë¼ë²¨ [0, 1, 2, ...]
            scores: ì‹ ë¢°ë„ ì ìˆ˜ [0.95, 0.87, ...]
            title_prefix: ì œëª© ì ‘ë‘ì‚¬ ("GT" ë˜ëŠ” "Pred")

        Returns:
            annotated_image: ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
        """
        img = image.copy()

        for i, (box, label_idx) in enumerate(zip(boxes, labels)):
            x1, y1, x2, y2 = map(int, box)
            class_name = self.class_names[int(label_idx)]
            color = self.colors[class_name]

            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)

            # ë¼ë²¨ í…ìŠ¤íŠ¸
            if scores is not None:
                text = f"{class_name} {scores[i]:.2f}"
            else:
                text = class_name

            # í…ìŠ¤íŠ¸ ë°°ê²½
            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(img, (x1, y1-25), (x1+text_size[0], y1), color, -1)

            # í…ìŠ¤íŠ¸
            cv2.putText(img, text, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)

        return img

    def log_validation_images(self, model, val_dataset_path, num_images=10, epoch=None):
        """
        ê²€ì¦ ì´ë¯¸ì§€ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ W&Bì— ë¡œê¹…

        Args:
            model: í•™ìŠµëœ YOLO ëª¨ë¸
            val_dataset_path: ê²€ì¦ ë°ì´í„°ì…‹ ê²½ë¡œ
            num_images: ë¡œê¹…í•  ì´ë¯¸ì§€ ìˆ˜
            epoch: í˜„ì¬ ì—í­ (ì„ íƒì )
        """
        val_images_path = Path(val_dataset_path) / 'val' / 'images'
        val_labels_path = Path(val_dataset_path) / 'val' / 'labels'

        if not val_images_path.exists():
            print("âš ï¸  ê²€ì¦ ì´ë¯¸ì§€ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ëœë¤ ì´ë¯¸ì§€ ì„ íƒ
        image_files = list(val_images_path.glob('*.[jp][pn][g]'))
        selected_images = random.sample(image_files, min(num_images, len(image_files)))

        wandb_images = []

        for img_path in selected_images:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = cv2.imread(str(img_path))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            h, w = image.shape[:2]

            # Ground Truth ë¼ë²¨ ë¡œë“œ
            label_path = val_labels_path / (img_path.stem + '.txt')
            gt_boxes, gt_labels = self._load_yolo_labels(label_path, w, h)

            # ëª¨ë¸ ì˜ˆì¸¡
            results = model.predict(str(img_path), verbose=False)
            pred_boxes = []
            pred_labels = []
            pred_scores = []

            if results and len(results) > 0 and results[0].boxes is not None:
                boxes = results[0].boxes
                pred_boxes = boxes.xyxy.cpu().numpy()
                pred_labels = boxes.cls.cpu().numpy()
                pred_scores = boxes.conf.cpu().numpy()

            # Ground Truth ì´ë¯¸ì§€
            gt_img = self.draw_boxes(image, gt_boxes, gt_labels, title_prefix="GT")

            # ì˜ˆì¸¡ ì´ë¯¸ì§€
            pred_img = self.draw_boxes(image, pred_boxes, pred_labels, pred_scores, title_prefix="Pred")

            # ë‚˜ë€íˆ ë¹„êµ ì´ë¯¸ì§€ ìƒì„±
            comparison_img = np.hstack([gt_img, pred_img])

            # ì œëª© ì¶”ê°€
            title_img = self._add_title(comparison_img, f"GT vs Pred: {img_path.name}")

            # W&B ì´ë¯¸ì§€ ê°ì²´ ìƒì„±
            wandb_img = wandb.Image(
                title_img,
                caption=f"Left: Ground Truth, Right: Prediction ({len(gt_labels)} GT, {len(pred_labels)} Pred)"
            )
            wandb_images.append(wandb_img)

        # W&Bì— ë¡œê¹…
        log_key = f"validation_images"
        if epoch is not None:
            log_key += f"_epoch_{epoch}"

        wandb.log({log_key: wandb_images})
        print(f"âœ… ê²€ì¦ ì´ë¯¸ì§€ {len(wandb_images)}ê°œë¥¼ W&Bì— ë¡œê¹…í–ˆìŠµë‹ˆë‹¤.")

    def log_test_results(self, model, test_dataset_path, num_images=20):
        """
        í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ W&Bì— ë¡œê¹…

        Args:
            model: í•™ìŠµëœ YOLO ëª¨ë¸
            test_dataset_path: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê²½ë¡œ
            num_images: ë¡œê¹…í•  ì´ë¯¸ì§€ ìˆ˜
        """
        test_images_path = Path(test_dataset_path) / 'test' / 'images'
        test_labels_path = Path(test_dataset_path) / 'test' / 'labels'

        if not test_images_path.exists():
            print("âš ï¸  í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì„±ëŠ¥ë³„ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜
        good_predictions = []  # ì •í™•í•œ ì˜ˆì¸¡
        bad_predictions = []   # ë¶€ì •í™•í•œ ì˜ˆì¸¡

        image_files = list(test_images_path.glob('*.[jp][pn][g]'))
        selected_images = random.sample(image_files, min(num_images*2, len(image_files)))

        for img_path in selected_images:
            # ì´ë¯¸ì§€ì™€ ë¼ë²¨ ë¡œë“œ
            image = cv2.imread(str(img_path))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            h, w = image.shape[:2]

            label_path = test_labels_path / (img_path.stem + '.txt')
            gt_boxes, gt_labels = self._load_yolo_labels(label_path, w, h)

            # ì˜ˆì¸¡
            results = model.predict(str(img_path), verbose=False)
            pred_boxes = []
            pred_labels = []
            pred_scores = []

            if results and len(results) > 0 and results[0].boxes is not None:
                boxes = results[0].boxes
                pred_boxes = boxes.xyxy.cpu().numpy()
                pred_labels = boxes.cls.cpu().numpy()
                pred_scores = boxes.conf.cpu().numpy()

            # ì˜ˆì¸¡ í’ˆì§ˆ í‰ê°€ (ê°„ë‹¨í•œ IoU ê¸°ë°˜)
            is_good_prediction = self._evaluate_prediction_quality(
                gt_boxes, gt_labels, pred_boxes, pred_labels, pred_scores
            )

            # ë¹„êµ ì´ë¯¸ì§€ ìƒì„±
            gt_img = self.draw_boxes(image, gt_boxes, gt_labels, title_prefix="GT")
            pred_img = self.draw_boxes(image, pred_boxes, pred_labels, pred_scores, title_prefix="Pred")
            comparison_img = np.hstack([gt_img, pred_img])
            title_img = self._add_title(comparison_img, f"{img_path.name}")

            wandb_img = wandb.Image(
                title_img,
                caption=f"GT: {len(gt_labels)}, Pred: {len(pred_labels)} objects"
            )

            if is_good_prediction and len(good_predictions) < num_images // 2:
                good_predictions.append(wandb_img)
            elif not is_good_prediction and len(bad_predictions) < num_images // 2:
                bad_predictions.append(wandb_img)

            if len(good_predictions) >= num_images // 2 and len(bad_predictions) >= num_images // 2:
                break

        # W&Bì— ë¡œê¹…
        if good_predictions:
            wandb.log({"test_good_predictions": good_predictions})
            print(f"âœ… ì¢‹ì€ ì˜ˆì¸¡ ê²°ê³¼ {len(good_predictions)}ê°œë¥¼ ë¡œê¹…í–ˆìŠµë‹ˆë‹¤.")

        if bad_predictions:
            wandb.log({"test_challenging_cases": bad_predictions})
            print(f"âš ï¸  ì–´ë ¤ìš´ ì˜ˆì¸¡ ì¼€ì´ìŠ¤ {len(bad_predictions)}ê°œë¥¼ ë¡œê¹…í–ˆìŠµë‹ˆë‹¤.")

    def _load_yolo_labels(self, label_path, img_w, img_h):
        """YOLO ë¼ë²¨ íŒŒì¼ ë¡œë“œ"""
        boxes = []
        labels = []

        if not label_path.exists():
            return boxes, labels

        with open(label_path, 'r') as f:
            for line in f.readlines():
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    x_center, y_center, width, height = map(float, parts[1:5])

                    # YOLO í˜•ì‹ì„ ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
                    x1 = int((x_center - width/2) * img_w)
                    y1 = int((y_center - height/2) * img_h)
                    x2 = int((x_center + width/2) * img_w)
                    y2 = int((y_center + height/2) * img_h)

                    boxes.append([x1, y1, x2, y2])
                    labels.append(class_id)

        return boxes, labels

    def _evaluate_prediction_quality(self, gt_boxes, gt_labels, pred_boxes, pred_labels, pred_scores, iou_threshold=0.5):
        """ì˜ˆì¸¡ í’ˆì§ˆ í‰ê°€ (ê°„ë‹¨í•œ IoU ê¸°ë°˜)"""
        if len(gt_boxes) == 0 and len(pred_boxes) == 0:
            return True  # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì •í™•
        if len(gt_boxes) == 0 or len(pred_boxes) == 0:
            return False  # í•˜ë‚˜ë§Œ ìˆìœ¼ë©´ ë¶€ì •í™•

        # ê°„ë‹¨í•œ ë§¤ì¹­ (ì‹¤ì œë¡œëŠ” Hungarian algorithm ì‚¬ìš© ê¶Œì¥)
        matched = 0
        for gt_box, gt_label in zip(gt_boxes, gt_labels):
            for pred_box, pred_label, pred_score in zip(pred_boxes, pred_labels, pred_scores):
                if abs(gt_label - pred_label) < 0.5 and pred_score > 0.5:  # ê°™ì€ í´ë˜ìŠ¤
                    iou = self._calculate_iou(gt_box, pred_box)
                    if iou > iou_threshold:
                        matched += 1
                        break

        # ë§¤ì¹­ëœ ë¹„ìœ¨ì´ 50% ì´ìƒì´ë©´ ì¢‹ì€ ì˜ˆì¸¡
        return matched / len(gt_boxes) >= 0.5

    def _calculate_iou(self, box1, box2):
        """IoU ê³„ì‚°"""
        x1, y1, x2, y2 = box1
        x1_p, y1_p, x2_p, y2_p = box2

        # êµì§‘í•© ì˜ì—­
        xi1 = max(x1, x1_p)
        yi1 = max(y1, y1_p)
        xi2 = min(x2, x2_p)
        yi2 = min(y2, y2_p)

        if xi2 <= xi1 or yi2 <= yi1:
            return 0

        inter_area = (xi2 - xi1) * (yi2 - yi1)
        box1_area = (x2 - x1) * (y2 - y1)
        box2_area = (x2_p - x1_p) * (y2_p - y1_p)
        union_area = box1_area + box2_area - inter_area

        return inter_area / union_area if union_area > 0 else 0

    def _add_title(self, image, title):
        """ì´ë¯¸ì§€ ìƒë‹¨ì— ì œëª© ì¶”ê°€"""
        title_height = 30
        title_img = np.ones((title_height, image.shape[1], 3), dtype=np.uint8) * 50

        # ì œëª© í…ìŠ¤íŠ¸
        cv2.putText(title_img, title, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

        # ì œëª©ê³¼ ì´ë¯¸ì§€ ê²°í•©
        return np.vstack([title_img, image])


def log_training_samples(dataset_path, class_names, num_samples=10):
    """
    í•™ìŠµ ì‹œì‘ ì „ ë°ì´í„°ì…‹ ìƒ˜í”Œ ë¡œê¹…

    Args:
        dataset_path: ë°ì´í„°ì…‹ ê²½ë¡œ
        class_names: í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        num_samples: ë¡œê¹…í•  ìƒ˜í”Œ ìˆ˜
    """
    visualizer = WandBVisualizer(class_names)

    train_images_path = Path(dataset_path) / 'train' / 'images'
    train_labels_path = Path(dataset_path) / 'train' / 'labels'

    if not train_images_path.exists():
        print("âš ï¸  í•™ìŠµ ì´ë¯¸ì§€ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    image_files = list(train_images_path.glob('*.[jp][pn][g]'))
    selected_images = random.sample(image_files, min(num_samples, len(image_files)))

    wandb_images = []
    class_counts = {name: 0 for name in class_names}

    for img_path in selected_images:
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(img_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        h, w = image.shape[:2]

        # ë¼ë²¨ ë¡œë“œ
        label_path = train_labels_path / (img_path.stem + '.txt')
        boxes, labels = visualizer._load_yolo_labels(label_path, w, h)

        # í´ë˜ìŠ¤ ì¹´ìš´íŠ¸
        for label in labels:
            class_counts[class_names[label]] += 1

        # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        annotated_img = visualizer.draw_boxes(image, boxes, labels, title_prefix="Train")
        title_img = visualizer._add_title(annotated_img, f"Training Sample: {img_path.name}")

        wandb_img = wandb.Image(
            title_img,
            caption=f"Objects: {len(labels)}"
        )
        wandb_images.append(wandb_img)

    # W&Bì— ë¡œê¹…
    wandb.log({
        "training_samples": wandb_images,
        "class_distribution": class_counts
    })

    print(f"âœ… í•™ìŠµ ìƒ˜í”Œ {len(wandb_images)}ê°œë¥¼ W&Bì— ë¡œê¹…í–ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬: {class_counts}")